{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is essentially this Python Jupyter Notebook by Google:\n",
    "# https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\n",
    "# refactored to run as a regular Python script\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from six.moves import urllib\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from distutils.version import StrictVersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module level variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTOS_DIR = \"C:/TensorFlow/models/research/object_detection/protos\"\n",
    "MIN_NUM_PY_FILES_IN_PROTOS_DIR = 5\n",
    "\n",
    "DOWNLOAD_MODEL_FROM_LOC = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# choose either MobileNet or Inception\n",
    "# MobileNet is a smaller download and runs faster, but is less accurate\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "# MODEL_NAME = 'ssd_inception_v2_coco_2017_11_17'\n",
    "\n",
    "MODEL_FILE_NAME = MODEL_NAME + '.tar.gz'\n",
    "\n",
    "MODEL_SAVE_DIR_LOC = \"C:/TensorFlow/models/research/object_detection\"\n",
    "FROZEN_INFERENCE_GRAPH_LOC = MODEL_SAVE_DIR_LOC + \"/\" + MODEL_NAME + \"/\" + \"frozen_inference_graph.pb\"\n",
    "LABEL_MAP_LOC = \"C:/TensorFlow/models/research/object_detection/data/mscoco_label_map.pbtxt\"\n",
    "TEST_IMAGES_DIR = \"C:/TensorFlow/models/research/object_detection/test_images\"\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"starting program . . .\")\n",
    "\n",
    "    if not checkIfNecessaryPathsAndFilesExist():\n",
    "        return\n",
    "    # end if\n",
    "\n",
    "    # now that we've checked for the protoc compile, import the TensorFlow models repo utils content\n",
    "    from utils import label_map_util\n",
    "    from utils import visualization_utils as vis_util\n",
    "\n",
    "    # if TensorFlow version is too old, show error message and bail\n",
    "    # this next comment line is necessary to avoid a false warning if using the editor PyCharm\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    if StrictVersion(tf.__version__) < StrictVersion('1.5.0'):\n",
    "        print('error: Please upgrade your tensorflow installation to v1.5.* or later!')\n",
    "        return\n",
    "    # end if\n",
    "\n",
    "    # if the frozen inference graph file does not already exist, download the model tar file and unzip it\n",
    "    try:\n",
    "        if not os.path.exists(FROZEN_INFERENCE_GRAPH_LOC):\n",
    "            # if the model tar file has not already been downloaded, download it\n",
    "            if not os.path.exists(os.path.join(MODEL_SAVE_DIR_LOC, MODEL_FILE_NAME)):\n",
    "                # download the model\n",
    "                print(\"downloading model . . .\")\n",
    "                # instantiate a URLopener object, then download the file\n",
    "                opener = urllib.request.URLopener()\n",
    "                opener.retrieve(DOWNLOAD_MODEL_FROM_LOC + MODEL_FILE_NAME, os.path.join(MODEL_SAVE_DIR_LOC, MODEL_FILE_NAME))\n",
    "            # end if\n",
    "\n",
    "            # unzip the tar to get the frozen inference graph\n",
    "            print(\"unzipping model . . .\")\n",
    "            tar_file = tarfile.open(os.path.join(MODEL_SAVE_DIR_LOC, MODEL_FILE_NAME))\n",
    "            for file in tar_file.getmembers():\n",
    "                file_name = os.path.basename(file.name)\n",
    "                if 'frozen_inference_graph.pb' in file_name:\n",
    "                    tar_file.extract(file, MODEL_SAVE_DIR_LOC)\n",
    "                # end if\n",
    "            # end for\n",
    "        # end if\n",
    "    except Exception as e:\n",
    "        print(\"error downloading or unzipping model: \"   + str(e))\n",
    "        return\n",
    "    # end try\n",
    "\n",
    "    # if the frozen inference graph does not exist after the above, show an error message and bail\n",
    "    if not os.path.exists(FROZEN_INFERENCE_GRAPH_LOC):\n",
    "        print(\"unable to get / create the frozen inference graph\")\n",
    "        return\n",
    "    # end if\n",
    "\n",
    "    # load the frozen model into memory\n",
    "    print(\"loading frozen model into memory . . .\")\n",
    "    detection_graph = tf.Graph()\n",
    "    try:\n",
    "        with detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(FROZEN_INFERENCE_GRAPH_LOC, 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "            # end with\n",
    "        # end with\n",
    "    except Exception as e:\n",
    "        print(\"error loading the frozen model into memory: \" + str(e))\n",
    "        return\n",
    "    # end try\n",
    "\n",
    "    # load the label map\n",
    "    print(\"loading label map . . .\")\n",
    "    label_map = label_map_util.load_labelmap(LABEL_MAP_LOC)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "    print(\"starting object detection . . .\")\n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "            for fileName in os.listdir(TEST_IMAGES_DIR):\n",
    "                if fileName.endswith(\".jpg\"):\n",
    "                    image_np = cv2.imread(os.path.join(TEST_IMAGES_DIR, fileName))\n",
    "                    if image_np is not None:\n",
    "                        # Definite input and output Tensors for detection_graph\n",
    "                        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                        # Each box represents a part of the image where a particular object was detected.\n",
    "                        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                        # Each score represent how level of confidence for each of the objects.\n",
    "                        # Score is shown on the result image, together with the class label.\n",
    "                        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "                        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "                        # Actual detection.\n",
    "                        (boxes, scores, classes, num) = sess.run(\n",
    "                            [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                            feed_dict={image_tensor: image_np_expanded})\n",
    "                        # Visualization of the results of a detection.\n",
    "                        vis_util.visualize_boxes_and_labels_on_image_array(image_np,\n",
    "                                                                           np.squeeze(boxes),\n",
    "                                                                           np.squeeze(classes).astype(np.int32),\n",
    "                                                                           np.squeeze(scores),\n",
    "                                                                           category_index,\n",
    "                                                                           use_normalized_coordinates=True,\n",
    "                                                                           line_thickness=8)\n",
    "                        cv2.imshow(\"result\", image_np)\n",
    "                        cv2.waitKey()\n",
    "                    # end if\n",
    "                # end if\n",
    "            # end for\n",
    "        # end with\n",
    "    # end with\n",
    "# end main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfNecessaryPathsAndFilesExist():\n",
    "    if not os.path.exists(PROTOS_DIR):\n",
    "        print('ERROR: PROTOS_DIR \"' + PROTOS_DIR + '\" does not seem to exist')\n",
    "        print('Did you compile protoc into the TensorFlow models repository?')\n",
    "        return False\n",
    "    # end if\n",
    "\n",
    "    # count the number of .py files in the protos directory, there should be many (20+)\n",
    "    numPyFilesInProtosDir = 0\n",
    "    for fileName in os.listdir(PROTOS_DIR):\n",
    "        if fileName.endswith(\".py\"):\n",
    "            numPyFilesInProtosDir += 1\n",
    "        # end if\n",
    "    # end for\n",
    "\n",
    "    # if there are not enough .py files in the protos directory then protoc must not have been compiled,\n",
    "    # so show an error and return False\n",
    "    if numPyFilesInProtosDir < MIN_NUM_PY_FILES_IN_PROTOS_DIR:\n",
    "        print('ERROR: less than ' + str(MIN_NUM_PY_FILES_IN_PROTOS_DIR) + ' .py files were found in PROTOS_DIR' + PROTOS_DIR)\n",
    "        print('Did you compile protoc into the TensorFlow models repository?')\n",
    "        return False\n",
    "    # end if\n",
    "\n",
    "    if not os.path.exists(MODEL_SAVE_DIR_LOC):\n",
    "        print('ERROR: MODEL_SAVE_DIR_LOC \"' + MODEL_SAVE_DIR_LOC + '\" does not seem to exist')\n",
    "        return False\n",
    "    # end if\n",
    "\n",
    "    if not os.path.exists(LABEL_MAP_LOC):\n",
    "        print('ERROR: LABEL_MAP_LOC \"' + LABEL_MAP_LOC + '\" does not seem to exist')\n",
    "        return False\n",
    "    # end if\n",
    "\n",
    "    if not os.path.exists(TEST_IMAGES_DIR):\n",
    "        print('ERROR: TEST_IMAGES_DIR \"' + TEST_IMAGES_DIR + '\" does not seem to exist')\n",
    "        return False\n",
    "    # end if\n",
    "\n",
    "    return True\n",
    "# end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting program . . .\n",
      "loading frozen model into memory . . .\n",
      "loading label map . . .\n",
      "starting object detection . . .\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
