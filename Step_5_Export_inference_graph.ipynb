{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original file by Google:\n",
    "# https://github.com/tensorflow/models/blob/master/research/object_detection/export_inference_graph.py\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from google.protobuf import text_format\n",
    "from object_detection import exporter\n",
    "from object_detection.protos import pipeline_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module-level variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_TYPE can be \"image_tensor\", \"encoded_image_string_tensor\", or \"tf_example\"\n",
    "INPUT_TYPE = \"image_tensor\"\n",
    "\n",
    "# If INPUT_TYPE is \"image_tensor\", INPUT_SHAPE can explicitly set.  The shape of this input tensor to a fixed size.\n",
    "# The dimensions are to be provided as a comma-separated list of integers. A value of -1 can be used for unknown dimensions.\n",
    "# If not specified, for an image_tensor, the default shape will be partially specified as [None, None, None, 3]\n",
    "INPUT_SHAPE = None\n",
    "\n",
    "# the location of the big config file\n",
    "PIPELINE_CONFIG_LOC =  os.getcwd() + \"/\" + \"ssd_inception_v2_coco.config\"\n",
    "\n",
    "# the final checkpoint result of the training process\n",
    "TRAINED_CHECKPOINT_PREFIX_LOC = os.getcwd() + \"/training_data/model.ckpt-500\"\n",
    "\n",
    "# the output directory to place the inference graph data, note that it's ok if this directory does not already exist\n",
    "# because the call to export_inference_graph() below will create this directory if it does not exist already\n",
    "OUTPUT_DIR = os.getcwd() + \"/\" + \"inference_graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    print(\"starting script . . .\")\n",
    "\n",
    "    if not checkIfNecessaryPathsAndFilesExist():\n",
    "        return\n",
    "    # end if\n",
    "\n",
    "    print(\"calling TrainEvalPipelineConfig() . . .\")\n",
    "    trainEvalPipelineConfig = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "\n",
    "    print(\"checking and merging \" + os.path.basename(PIPELINE_CONFIG_LOC) + \" into trainEvalPipelineConfig . . .\")\n",
    "    with tf.gfile.GFile(PIPELINE_CONFIG_LOC, 'r') as f:\n",
    "        text_format.Merge(f.read(), trainEvalPipelineConfig)\n",
    "    # end with\n",
    "\n",
    "    print(\"calculating input shape . . .\")\n",
    "    if INPUT_SHAPE:\n",
    "        input_shape = [ int(dim) if dim != '-1' else None for dim in INPUT_SHAPE.split(',') ]\n",
    "    else:\n",
    "        input_shape = None\n",
    "    # end if\n",
    "\n",
    "    print(\"calling export_inference_graph() . . .\")\n",
    "    exporter.export_inference_graph(INPUT_TYPE, trainEvalPipelineConfig, TRAINED_CHECKPOINT_PREFIX_LOC, OUTPUT_DIR, input_shape)\n",
    "\n",
    "    print(\"done !!\")\n",
    "# end main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfNecessaryPathsAndFilesExist():\n",
    "    if not os.path.exists(PIPELINE_CONFIG_LOC):\n",
    "        print('ERROR: PIPELINE_CONFIG_LOC \"' + PIPELINE_CONFIG_LOC + '\" does not seem to exist')\n",
    "        return False\n",
    "    # end if\n",
    "\n",
    "    # TRAINED_CHECKPOINT_PREFIX_LOC is a special case because there is no actual file with this name.\n",
    "    # i.e. if TRAINED_CHECKPOINT_PREFIX_LOC is:\n",
    "    # \"C:\\Users\\cdahms\\Documents\\TensorFlow_Tut_3_Object_Detection_Walk-through\\training_data\\training_data\\model.ckpt-500\"\n",
    "    # this exact file does not exist, but there should be 3 files including this name, which would be:\n",
    "    # \"model.ckpt-500.data-00000-of-00001\"\n",
    "    # \"model.ckpt-500.index\"\n",
    "    # \"model.ckpt-500.meta\"\n",
    "    # therefore it's necessary to verify that the stated directory exists and then check if there are at least three files\n",
    "    # in the stated directory that START with the stated name\n",
    "\n",
    "    # break out the directory location and the file prefix\n",
    "    trainedCkptPrefixPath, filePrefix = os.path.split(TRAINED_CHECKPOINT_PREFIX_LOC)\n",
    "\n",
    "    # return false if the directory does not exist\n",
    "    if not os.path.exists(trainedCkptPrefixPath):\n",
    "        print('ERROR: directory \"' + trainedCkptPrefixPath + '\" does not seem to exist')\n",
    "        print('was the training completed successfully?')\n",
    "        return False\n",
    "    # end if\n",
    "\n",
    "    # count how many files in the stated directory start with the stated prefix\n",
    "    numFilesThatStartWithPrefix = 0\n",
    "    for fileName in os.listdir(trainedCkptPrefixPath):\n",
    "        if fileName.startswith(filePrefix):\n",
    "            numFilesThatStartWithPrefix += 1\n",
    "        # end if\n",
    "    # end if\n",
    "\n",
    "    # if less than 3 files start with the stated prefix, return false\n",
    "    if numFilesThatStartWithPrefix < 3:\n",
    "        print('ERROR: 3 files statring with \"' + filePrefix + '\" do not seem to be present in the directory \"' + trainedCkptPrefixPath + '\"')\n",
    "        print('was the training completed successfully?')\n",
    "    # end if\n",
    "\n",
    "    # if we get here the necessary directories and files are present, so return True\n",
    "    return True\n",
    "# end function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting script . . .\n",
      "calling TrainEvalPipelineConfig() . . .\n",
      "checking and merging ssd_inception_v2_coco.config into trainEvalPipelineConfig . . .\n",
      "calculating input shape . . .\n",
      "calling export_inference_graph() . . .\n",
      "WARNING:tensorflow:From C:\\Users\\Michael\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From C:\\TensorFlow\\models\\research\\object_detection\\exporter.py:362: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From C:\\TensorFlow\\models\\research\\object_detection\\exporter.py:518: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "WARNING:tensorflow:From C:\\Users\\Michael\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.remove_training_nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166 ops no flops stats due to incomplete shapes.\n",
      "166 ops no flops stats due to incomplete shapes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Michael\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Michael\\NW University Object Detection\\Running folder/training_data/model.ckpt-500\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Michael\\NW University Object Detection\\Running folder/training_data/model.ckpt-500\n",
      "WARNING:tensorflow:From C:\\Users\\Michael\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\tools\\freeze_graph.py:232: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From C:\\Users\\Michael\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 410 variables.\n",
      "INFO:tensorflow:Converted 410 variables to const ops.\n",
      "WARNING:tensorflow:From C:\\TensorFlow\\models\\research\\object_detection\\exporter.py:291: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: C:\\Users\\Michael\\NW University Object Detection\\Running folder/inference_graph\\saved_model\\saved_model.pb\n",
      "INFO:tensorflow:Writing pipeline config file to C:\\Users\\Michael\\NW University Object Detection\\Running folder/inference_graph\\pipeline.config\n",
      "done !!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error because a maximum was reached for training, but it works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
